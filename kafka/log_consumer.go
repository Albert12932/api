package kafka

import (
	"context"
	"encoding/json"
	"log"
	"os"

	"github.com/IBM/sarama"
)

// LogEntry —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è –ª–æ–≥–æ–≤
type LogEntry struct {
	Timestamp string `json:"timestamp"`
	UserID    int    `json:"user_id"`
	Action    string `json:"action"`
	Details   string `json:"details"`
}

// KafkaLogConsumer —á–∏—Ç–∞–µ—Ç –ª–æ–≥–∏ –∏–∑ Kafka
type KafkaLogConsumer struct {
	Consumer sarama.ConsumerGroup
	Topic    string
}

// NewKafkaLogConsumer —Å–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–π Kafka Consumer
func NewKafkaLogConsumer(brokers []string, group, topic string) (*KafkaLogConsumer, error) {
	config := sarama.NewConfig()
	config.Consumer.Return.Errors = true
	config.Version = sarama.V3_0_0_0
	config.Consumer.Group.Rebalance.GroupStrategies = []sarama.BalanceStrategy{
		sarama.NewBalanceStrategyRoundRobin(),
	}

	consumer, err := sarama.NewConsumerGroup(brokers, group, config)
	if err != nil {
		log.Printf("‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è Kafka Log Consumer: %v", err)
		return nil, err
	}

	log.Println("‚úÖ Kafka Log Consumer —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

	return &KafkaLogConsumer{
		Consumer: consumer,
		Topic:    topic,
	}, nil
}

// ConsumeLogs —á–∏—Ç–∞–µ—Ç –ª–æ–≥–∏ –∏–∑ Kafka –∏ –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –∏—Ö –≤ `logs.json`
func (kc *KafkaLogConsumer) ConsumeLogs(ctx context.Context) {
	file, err := os.OpenFile("logs.json", os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
	if err != nil {
		log.Fatalf("‚ùå –û—à–∏–±–∫–∞ –æ—Ç–∫—Ä—ã—Ç–∏—è —Ñ–∞–π–ª–∞ –ª–æ–≥–æ–≤: %v", err)
	}
	defer file.Close()

	handler := &logConsumerHandler{file}

	for {
		select {
		case <-ctx.Done(): // –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –∑–∞–≤–µ—Ä—à—ë–Ω (Ctrl+C), –≤—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞
			log.Println("üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ Kafka Log Consumer...")
			return
		default:
			err := kc.Consumer.Consume(ctx, []string{kc.Topic}, handler)
			if err != nil {
				// –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ —Å–≤—è–∑–∞–Ω–∞ —Å –∑–∞–∫—Ä—ã—Ç–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, –≤—ã—Ö–æ–¥–∏–º –±–µ–∑ –æ—à–∏–±–∫–∏
				if err == context.Canceled || err.Error() == "kafka: tried to use a consumer group that was closed" {
					log.Println("‚úÖ Kafka Consumer –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∑–∞–≤–µ—Ä—à—ë–Ω")
					return
				}
				log.Printf("‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –ª–æ–≥–æ–≤ –∏–∑ Kafka: %v\n", err)
			}
		}
	}
}

// Close –∑–∞–∫—Ä—ã–≤–∞–µ—Ç Consumer
func (kc *KafkaLogConsumer) Close() {
	if err := kc.Consumer.Close(); err != nil {
		log.Printf("‚ùå –û—à–∏–±–∫–∞ –∑–∞–∫—Ä—ã—Ç–∏—è Kafka Log Consumer: %v\n", err)
	}
	log.Println("‚úÖ Kafka Log Consumer –∑–∞–∫—Ä—ã—Ç")
}

// logConsumerHandler –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ Kafka
type logConsumerHandler struct {
	File *os.File
}

func (h logConsumerHandler) Setup(sarama.ConsumerGroupSession) error   { return nil }
func (h logConsumerHandler) Cleanup(sarama.ConsumerGroupSession) error { return nil }
func (h logConsumerHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error {
	for message := range claim.Messages() {
		var logEntry LogEntry
		err := json.Unmarshal(message.Value, &logEntry)
		if err != nil {
			log.Printf("‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: %v\n JSON: %s\n", err, string(message.Value))
			continue
		}

		// –ï—Å–ª–∏ details –ø—É—Å—Ç–æ–µ, –∑–∞–º–µ–Ω—è–µ–º –µ–≥–æ
		if logEntry.Details == "" {
			logEntry.Details = "No details provided"
		}

		// –ó–∞–ø–∏—Å—ã–≤–∞–µ–º JSON –≤ —Ñ–∞–π–ª
		jsonData, err := json.Marshal(logEntry)
		if err != nil {
			log.Printf("‚ùå –û—à–∏–±–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è JSON: %v\n", err)
			continue
		}

		_, err = h.File.Write(jsonData)
		if err != nil {
			log.Printf("‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –≤ —Ñ–∞–π–ª: %v\n", err)
		}

		// –î–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏ –¥–ª—è —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏
		h.File.WriteString("\n")

		// –õ–æ–≥–∏—Ä—É–µ–º –≤ –∫–æ–Ω—Å–æ–ª—å
		log.Printf("üì© –õ–æ–≥ –∑–∞–ø–∏—Å–∞–Ω: %s\n", string(jsonData))

		session.MarkMessage(message, "")
	}
	return nil
}
